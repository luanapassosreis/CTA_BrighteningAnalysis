{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "affd61cd-8b95-464c-8ae0-69bb499b3e09",
   "metadata": {},
   "source": [
    "# Imports, Functions and Dataframes for the 4LAC Analysis\n",
    "\n",
    "In this file you will find:\n",
    "\n",
    "- Imports that are necessary on other files from this repository\n",
    "- Functions that are used on other files as well\n",
    "- Dataframes with the separated Classes imported from the online Catalog Repository for a 3-day and a weekly cadence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d170d0-fd99-41e9-a4b3-f74600f8f01d",
   "metadata": {},
   "source": [
    "Files that may help:\n",
    "\n",
    "- Fermi LAT Light Curve Repository: https://fermi.gsfc.nasa.gov/ssc/data/access/lat/LightCurveRepository/\n",
    "- LAT 10-year Source Catalog (4FGL-DR2): https://fermi.gsfc.nasa.gov/ssc/data/access/lat/10yr_catalog/\n",
    "- Fermi Light Curve Repository Data Description: https://fermi.gsfc.nasa.gov/ssc/data/access/lat/LightCurveRepository/table_description.html\n",
    "- The Likelihood Analysis of EGRET Data: https://ui.adsabs.harvard.edu/abs/1996ApJ...461..396M/abstract\n",
    "- Fermi Large Area Telescope Fourth Source Catalog Collaboration paper: https://arxiv.org/pdf/1902.10045.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f45b5fb-0b5f-41ba-9349-ddf46e2a2e1d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "897c141b-556c-437f-8232-1872ebd52798",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Astro imports\n",
    "\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "from astropy.table import QTable\n",
    "import astropy.units as u\n",
    "from astropy.io import ascii\n",
    "import os\n",
    "import json\n",
    "import urllib.request\n",
    "\n",
    "from astropy import units as u\n",
    "\n",
    "from astropy.time import Time,TimeUnix\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b1bbbab-e47c-421f-8ac9-64dac97e3d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Other imports\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.optimize as sp\n",
    "import scipy.odr.odrpack as odrpack\n",
    "from scipy import signal, integrate\n",
    "from scipy.fft import fft, fftfreq\n",
    "import numpy as np\n",
    "import statistics\n",
    "import csv\n",
    "import math\n",
    "from scipy.fft import fft, fftfreq\n",
    "\n",
    "import matplotlib.ticker as mticker\n",
    "from matplotlib.ticker import FormatStrFormatter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f01036-5119-49b3-9f00-bf8e92f4e822",
   "metadata": {},
   "source": [
    "## Defining a path to the folder where all the files are at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c884acb-1a03-413d-a0bd-d3f8fd2facda",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CHANGE PATH HERE #####\n",
    "\n",
    "path = '/Users/luanareis/Documents/IC/AGNpop_taskforce'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04526e8-01bc-4340-88ca-fe3e113fdc1e",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24f493ff-4d06-40d2-b228-ce1b8f93be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## ---------- convert time from MET to UTC ----------\n",
    "def convert_MET_UTC(time_MET):\n",
    "    ########## Description ##########\n",
    "    # more info on time in LAT:\n",
    "    # https://fermi.gsfc.nasa.gov/ssc/data/analysis/documentation/Cicerone/Cicerone_Data/Time_in_ScienceTools.html\n",
    "    # ---------- Input ----------\n",
    "    # time_MET : time using MET (seconds) from January 1st, 2001 until now  (1D-array)\n",
    "    # ---------- Output ----------\n",
    "    # time in UTC                                                           (1D-array)\n",
    "    #################################\n",
    "    \n",
    "    # changing data to Unix (referencial of 1970)\n",
    "    time_Unix = Time(time_MET, format='unix', scale='utc')\n",
    "\n",
    "    # finding how many seconds are there from 1970 to January 1st, 2001\n",
    "    time_difference = Time('2001-01-01', format='iso', scale='utc')\n",
    "    time_difference.format = 'unix'\n",
    "    time_difference.value\n",
    "\n",
    "    # increased the diffence of time between 2001 and 1970 to my data\n",
    "    time_MET_copy = np.copy(time_MET)\n",
    "    time_MET_copy += time_difference.value\n",
    "\n",
    "    # transform into year: format='iso'\n",
    "    time_Unix = Time(time_MET_copy, format='unix', scale='utc')\n",
    "    time_Unix.format = 'iso'\n",
    "    time_Unix\n",
    "\n",
    "    # list with only date values, year, month and day\n",
    "    time_UTC = []\n",
    "    for i in range(len(time_Unix.value)):\n",
    "        time_UTC.append(datetime.strptime(time_Unix.value[i][:10], '%Y-%m-%d'))\n",
    "\n",
    "    return time_UTC\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## ---------- log-normal representation ----------\n",
    "def dNdE(E, E_0, K, alpha, beta=None):\n",
    "    ########## Description ##########\n",
    "    # ---------- Input ----------\n",
    "    # E     : value of the energy                               (1D-array)\n",
    "    # E_0   : value of the pivot_Energy in erg                  (float)\n",
    "    # K     : value of the flux_Density in erg-1 cm-2 s-1       (float)\n",
    "    # alpha : Index                                             (float)\n",
    "    # beta  : Beta (only for LogParabola SED_class)             (float)\n",
    "    # ---------- Output ----------\n",
    "    # log-normal representation value dN/dE in 'erg-1 cm-2 s-1' (1D-array)\n",
    "    #################################\n",
    "    \n",
    "    if (beta == None):\n",
    "        Y = K * ((E/E_0)**(-alpha))\n",
    "    else:\n",
    "        Y = K * ((E/E_0)**(-alpha - beta * np.log(E/E_0)))       \n",
    "    return Y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## ---------- Differential Flux ----------\n",
    "def diff_flux(E, E_0, K, alpha, beta=None):\n",
    "    ########## Description ##########\n",
    "    # ---------- Input ----------\n",
    "    # E     : value of the energy                          (1D-array)\n",
    "    # E_0   : value of the pivot_Energy in erg             (float)\n",
    "    # K     : value of the flux_Density in erg-1 cm-2 s-1  (float)\n",
    "    # alpha : Index                                        (float)\n",
    "    # beta  : Beta (only for LogParabola SED_class)        (float)\n",
    "    # ---------- Output ----------\n",
    "    # differential flux value E^2 dN/dE in 'erg cm-2 s-1'  (1D-array)\n",
    "    #################################\n",
    "    \n",
    "    if (beta == None):\n",
    "        Y = E**2 * K * ((E/E_0)**(-alpha))\n",
    "    else:\n",
    "        Y = E**2 * K * ((E/E_0)**(-alpha - beta * np.log(E/E_0)))     \n",
    "    return Y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## ---------- extract data from .json file ----------\n",
    "def extract_data_from_file(bins,file_name):\n",
    "    ########## Description ##########\n",
    "    # ---------- Input ----------\n",
    "    # file_name : name of .json file                          (string)\n",
    "    # ---------- Output ----------\n",
    "    # name : name of the source                               (string)\n",
    "    # time, flux : axis for Light Curve                       (array)\n",
    "    # time_error, flux_low_error, flux_high_error : error     (array)\n",
    "    # time_upper_lim, flux_upper_lim : upper limits           (array)\n",
    "    #################################\n",
    "    \n",
    "    if (bins == 'weekly'):\n",
    "        file = open(f'{path}/lightcurve_downloader/downloaded_lightcurves/weekly_lightcurves/{file_name}')\n",
    "    if (bins == '3-days'):\n",
    "        file = open(f'{path}/lightcurve_downloader/downloaded_lightcurves/3day_lightcurves/{file_name}')\n",
    "    \n",
    "    name = file_name[5:-5]\n",
    "    \n",
    "    # returns JSON object as a dictionary\n",
    "    data = json.load(file)\n",
    "    \n",
    "    # creating arrays to store the data\n",
    "    time = np.array(data['flux'])[:,0]     # 'flux' [i][0]\n",
    "    flux = np.array(data['flux'])[:,1]     # 'flux' [i][1]\n",
    "    \n",
    "    time_error      = np.array(data['flux_error'])[:,0]     # 'flux_error' [i][0]\n",
    "    flux_low_error  = np.array(data['flux_error'])[:,1]     # 'flux_error' [i][1]  - lower flux edge\n",
    "    flux_high_error = np.array(data['flux_error'])[:,2]     # 'flux_error' [i][2]  - high edge\n",
    "    \n",
    "    time_upper_lim  = np.array(data['flux_upper_limits'])[:,0]     # 'flux_upper_limits' [i][0]\n",
    "    flux_upper_lim  = np.array(data['flux_upper_limits'])[:,1]     # 'flux_upper_limits' [i][1]\n",
    "    \n",
    "    return name, time, flux, time_error, flux_low_error, flux_high_error, time_upper_lim, flux_upper_lim\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## ---------- Which dataframe to use based on the Synchroton Type ----------\n",
    "def synchr_type_dataframe(file_name):\n",
    "    ########## Description ##########\n",
    "    # ---------- Input ----------\n",
    "    # file_name : name of the file in .json         (string)\n",
    "    # ---------- Output ----------\n",
    "    # dataframe : which dataframe to use            (dataframe)\n",
    "    #################################\n",
    "    \n",
    "    ## ---------- Low Synchrotron Peak ----------\n",
    "    if (dfLSP['Source_Name'] == file_name[5:-5]).any():\n",
    "        dataframe = dfLSP\n",
    "\n",
    "    ## ---------- Intermediate Synchrotron Peak ----------\n",
    "    if (dfISP['Source_Name'] == file_name[5:-5]).any():\n",
    "        dataframe = dfISP\n",
    "        \n",
    "    ## ---------- High Synchrotron Peak ----------\n",
    "    if (dfHSP['Source_Name'] == file_name[5:-5]).any():\n",
    "        dataframe = dfHSP\n",
    "        \n",
    "    return dataframe\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## ---------- parameters from FITS table of 10-year observations ----------\n",
    "def extract_parameters_from_table(name, dataframe, flux):\n",
    "    ########## Description ##########\n",
    "    # ---------- Input ----------\n",
    "    # name : name of the source                                (string)\n",
    "    # dataframe : which df to use                              (dataframe)\n",
    "    # flux : flux of the source from .json file                (array)\n",
    "    # ---------- Output ----------\n",
    "    # E : energy                                               (array)\n",
    "    # dflux : differential flux                                (array)\n",
    "    # spec_type : spectrum type                                (string)\n",
    "    # flux_from_spectrum : integrated flux from the SED        (float)\n",
    "    #################################\n",
    "\n",
    "    # defining Energy\n",
    "    E = ((np.logspace(np.log10(0.1), np.log10(100), 100) * u.GeV).to('erg')).value     # log scale of Energy in erg\n",
    "\n",
    "    # get the index of each one\n",
    "    index = dataframe[dataframe['Source_Name'] == name].index\n",
    "\n",
    "    for i in index:\n",
    "\n",
    "        # Pivot_Energy in erg\n",
    "        E0 = ((dataframe.loc[i,'Pivot_Energy'] * u.MeV).to('erg')).value\n",
    "\n",
    "        ## ---------- PowerLaw ----------\n",
    "        if dataframe.loc[i,'SpectrumType'] == 'PowerLaw         ':\n",
    "            spec_type = \"PowerLaw\"\n",
    "\n",
    "            # PL_Flux_Density in erg-1 cm-2 s-1\n",
    "            K = ((dataframe.loc[i,'PL_Flux_Density'] * u.MeV**-1 * u.cm**-2 * u.s**-1).to('erg-1 cm-2 s-1')).value\n",
    "            # PL_Index\n",
    "            alpha = dataframe.loc[i,'PL_Index']\n",
    "\n",
    "            dflux = diff_flux(E, E0, K, alpha)\n",
    "\n",
    "            integralf = integrate.quad(lambda x: K * ((x/E0)**(-alpha)),\n",
    "                                           (0.1*u.GeV).to('erg').value, (100*u.GeV).to('erg').value)\n",
    "\n",
    "            flux_from_spectrum = integralf[0] # returning only the first value of integralflux\n",
    "\n",
    "        ## ---------- LogParabola ----------\n",
    "        elif dataframe.loc[i,'SpectrumType'] == 'LogParabola      ':\n",
    "            spec_type = \"LogParabola\"\n",
    "\n",
    "            # LP_Flux_Density in erg-1 cm-2 s-1\n",
    "            K = ((dataframe.loc[i,'LP_Flux_Density'] * u.MeV**-1 * u.cm**-2 * u.s**-1).to('erg-1 cm-2 s-1')).value\n",
    "            # LP_Index\n",
    "            alpha = dataframe.loc[i,'LP_Index']\n",
    "            # LP_beta\n",
    "            beta = dataframe.loc[i,'LP_beta']\n",
    "\n",
    "            dflux = diff_flux(E, E0, K, alpha, beta)\n",
    "\n",
    "            integralf = integrate.quad(lambda x: K * ((x/E0)**(-alpha - beta * np.log(x/E0))), \n",
    "                                          (0.1*u.GeV).to('erg').value, (100*u.GeV).to('erg').value)\n",
    "\n",
    "            flux_from_spectrum = integralf[0] # returning only the first value of integralflux\n",
    "\n",
    "        ## ---------- in case there is an error ----------\n",
    "        else:\n",
    "            print('### error ###')\n",
    "    \n",
    "        \n",
    "    return E, dflux, spec_type, flux_from_spectrum\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## ---------- relative difference between the flux and integral flux ----------\n",
    "def relative_difference(flux, flux_from_spectrum):\n",
    "    ########## Description ##########\n",
    "    # ---------- Input ----------\n",
    "    # flux : the light curve flux                                                         (float)\n",
    "    # flux_from_spectrum : integrated flux from the 10-years SED                          (float)\n",
    "    # ---------- Output ----------\n",
    "    # relative difference : relative difference between the average and integrated flux   (float)\n",
    "    #################################\n",
    "    \n",
    "    average_flux = np.average(flux)\n",
    "    \n",
    "    rel_difference = np.abs(flux_from_spectrum - average_flux) / average_flux\n",
    "    \n",
    "    return rel_difference\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## ---------- filtering the sources with a % difference between the average and integrated flux ----------\n",
    "def filter_percentage(name, flux, flux_from_spectrum, percentage):\n",
    "    ########## Description ##########\n",
    "    # ---------- Input ----------\n",
    "    # name : name of the source                                     (string)\n",
    "    # flux : the light curve flux                                   (float)\n",
    "    # flux_from_spectrum : integrated flux from the 10-years SED    (float)\n",
    "    # percentage : percentage we want to filter                     (float)\n",
    "    # ---------- Output ----------\n",
    "    # True / False (boolean) : if we include the source or not      (float)\n",
    "    #################################\n",
    "    \n",
    "    rel_difference = relative_difference(flux, flux_from_spectrum) *100\n",
    "    \n",
    "    print(f'Source {name} percentage:', np.round(rel_difference))\n",
    "    \n",
    "    if (rel_difference <= percentage):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## ---------- plot Spectral Energy Distribution ----------\n",
    "def plot_SED(E, dflux, power, name, spec_type, x_dlim, x_ulim, y_dlim, y_ulim):\n",
    "    ########## Description ##########\n",
    "    # ---------- Input ----------\n",
    "    # E : energy created by logspace from 0.1 to 100 GeV,\n",
    "    # given only the value in 'erg'                             (array)\n",
    "    # dflux : differential flux calculated by fuction           (array)\n",
    "    # power : power of the dflux                                (int)\n",
    "    # name  : name of the source                                (string)\n",
    "    # spect_type : Spectrum Type (logP/ powL)                   (string)\n",
    "    # x_dlim, x_ulim : limits of x axis                         (float)\n",
    "    # y_dlim, y_ulim : limits of y axis                         (float)\n",
    "    # ---------- Output ----------\n",
    "    # \n",
    "    #################################\n",
    "\n",
    "    plt.figure(figsize=(7,5), dpi=100)\n",
    "\n",
    "    plt.plot(((E*u.erg).to('GeV')).value, dflux*10**(power), '+', markersize=2, color='black')\n",
    "    plt.plot(((E*u.erg).to('GeV')).value, dflux*10**(power), '--', linewidth=0.4, color='black')\n",
    "\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.gca().xaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "    plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "\n",
    "    plt.xlim(x_dlim, x_ulim)\n",
    "    plt.ylim(y_dlim, y_ulim)\n",
    "\n",
    "    \n",
    "    plt.title(f'4FGL+{name} - {spec_type} Spectrum', fontsize='large')\n",
    "    plt.ylabel(r'$\\nu\\ F_{\\nu}$ [ $ 10^{- %d } $ erg $cm^{-2}$ $s^{-1}$]' % (power), fontsize=12)\n",
    "    plt.xlabel('Energy (GeV)', fontsize=12)\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## ---------- plot LightCurve ----------\n",
    "def plot_lc(name, time, flux, time_error, flux_low_error, flux_high_error,\n",
    "            time_upper_lim, flux_upper_lim, ylim, flux_from_spectrum):\n",
    "    ########## Description ##########\n",
    "    # ---------- Input ----------\n",
    "    # name: name of the source                                (string)\n",
    "    # time, flux : axis for Light Curve                       (array)\n",
    "    # time_error, flux_low_error, flux_high_error : error     (array)\n",
    "    # time_upper_lim, flux_upper_lim : upper limits           (array)\n",
    "    # ylim: limit of the y axis                               (float)\n",
    "    # flux_from_spectrum : integrated flux over 10-year SED   (float)\n",
    "    # ---------- Output ----------\n",
    "    # \n",
    "    #################################\n",
    "    \n",
    "    difference = relative_difference(flux, flux_from_spectrum)\n",
    "    print('difference:', difference)\n",
    "    \n",
    "    plt.figure(figsize=(17,5), dpi=300)\n",
    "\n",
    "    # flux\n",
    "    plt.plot(time, flux, '.', markersize=10, label='Flux Points')\n",
    "    plt.plot(time, flux, linewidth=0.4, color='black')\n",
    "\n",
    "    # upper_limits\n",
    "    plt.plot(time_upper_lim, flux_upper_lim, 'v', color='gray', markersize=3, alpha=0.45, label='Upper Limits')\n",
    "\n",
    "    # error_bar\n",
    "    # plt.plot(time_error, flux_low_error, 'x', color='green', markersize=3, alpha=0.3)  # visualize the error\n",
    "    # plt.plot(time_error, flux_high_error, 'x', color='red', markersize=3, alpha=0.3)   # visualize the error\n",
    "    plt.errorbar(time, flux, yerr=flux_high_error-flux, linewidth=0.2, color='black', alpha=0.9)\n",
    "    plt.errorbar(time, flux, yerr=flux-flux_low_error, linewidth=0.2, color='black', alpha=0.9)\n",
    "\n",
    "    # integrated flux\n",
    "    plt.hlines(y=flux_from_spectrum, xmin=np.min(time), xmax=np.max(time), linewidth=2, linestyles='dashed', color='r', label='Flux from Spectrum')\n",
    "    plt.hlines(y=np.average(flux), xmin=np.min(time), xmax=np.max(time), linewidth=2, linestyles='dashed', color='b', label='Average Flux')\n",
    "\n",
    "    # legend\n",
    "    plt.legend() # f'difference: {difference}'\n",
    "    \n",
    "    plt.ylim(0, ylim)\n",
    "    plt.title(f'4FGL+{name} Light Curve', fontsize='xx-large')\n",
    "    plt.ylabel('Photon Flux (0.1-100 GeV ph $cm^{-2}$ $s^{-1}$)', fontsize=12)\n",
    "    plt.xlabel('Time (MET s)', fontsize=12) # Date (UTC)\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_histogram(flux_proportion, bins1, bins2, x_low_lim, x_high_lim):\n",
    "    ########## Description ##########\n",
    "    # ---------- Input ----------\n",
    "    # flux_proportion : flux / integrated flux                 (array)\n",
    "    # bins1: name of the source                                (int)\n",
    "    # bins2 : axis for Light Curve                             (int)\n",
    "    # x_low_lim: inferior limit of x axis                      (float)\n",
    "    # x_high_lim: superior limit of x axis                     (float)\n",
    "    # ---------- Output ----------\n",
    "    # \n",
    "    #################################\n",
    "\n",
    "    n, bins, patches = plt.hist(flux_proportion, bins1, density=True, facecolor='g', alpha=0.75)\n",
    "    n, bins, patches = plt.hist(flux_proportion, bins2, density=True, facecolor='red', alpha=0.75)\n",
    "\n",
    "    plt.xlabel('Flux / Integrated Flux')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    plt.xlim(x_low_lim, x_high_lim)\n",
    "    plt.yscale('log')\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39017866-5846-4716-9f7c-2731412f7677",
   "metadata": {},
   "source": [
    "## Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6c9bf3a-b153-4e1c-8635-ba576d0f2f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ---------- Low Synchrotron Peak ----------\n",
    "dfLSP = pd.read_csv(f'{path}/4LAC_catalog_generator_v2/LSP_data.csv')\n",
    "## ---------- Intermediate Synchrotron Peak ----------\n",
    "dfISP = pd.read_csv(f'{path}/4LAC_catalog_generator_v2/ISP_data.csv')\n",
    "## ---------- High Synchrotron Peak ----------\n",
    "dfHSP = pd.read_csv(f'{path}/4LAC_catalog_generator_v2/HSP_data.csv')\n",
    "\n",
    "## ---------- Whole Dataframe ----------\n",
    "dat = pd.read_csv(f'{path}/4LAC_catalog_generator_v2/whole_dataframe.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcf708b-243e-4cff-867b-5e66b786fe3a",
   "metadata": {},
   "source": [
    "## Filtering the .json files that are on each table (filter by Synchrotron Type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a14a459-1b80-4018-9332-25a2a06a32ed",
   "metadata": {},
   "source": [
    "### 3 days bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e93fc220-e533-433e-ab22-b98b6488be85",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_downloaded_3days = os.listdir(f'{path}/lightcurve_downloader/downloaded_lightcurves/3day_lightcurves') ## 3day_lightcurves folder\n",
    "\n",
    "## Create a list with the downloaded lightcurves that have a corresponding item in the table\n",
    "lc_downloaded_LSP_3days = [] # low\n",
    "lc_downloaded_ISP_3days = [] # intermediate\n",
    "lc_downloaded_HSP_3days = [] # high\n",
    "\n",
    "for file in lc_downloaded_3days:\n",
    "    ## ---------- Low Synchrotron Peak ----------\n",
    "    if (dfLSP['Source_Name'] == file[5:-5]).any():\n",
    "        lc_downloaded_LSP_3days.append(f'4FGL+{file[5:-5]}.json')\n",
    "        \n",
    "    ## ---------- Intermediate Synchrotron Peak ----------\n",
    "    if (dfISP['Source_Name'] == file[5:-5]).any():\n",
    "        lc_downloaded_ISP_3days.append(f'4FGL+{file[5:-5]}.json')\n",
    "        \n",
    "    ## ---------- High Synchrotron Peak ----------\n",
    "    if (dfHSP['Source_Name'] == file[5:-5]).any():\n",
    "        lc_downloaded_HSP_3days.append(f'4FGL+{file[5:-5]}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "094cb452-11d8-415a-a75d-1c77e1cbe422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- 3-day bin ---------------\n",
      "\n",
      "# of sources in the dataframes:\n",
      "dfLSP: 1538\n",
      "dfISP: 508\n",
      "dfHSP: 548\n",
      "---> total: 2594\n",
      "dat: 3511\n",
      "\n",
      "# of lcs downloaded:\n",
      "lc_downloaded_LSP_3days: 465\n",
      "lc_downloaded_ISP_3days: 60\n",
      "lc_downloaded_HSP_3days: 66\n",
      "---> total: 591\n",
      "lc_downloaded_3days: 683\n",
      "\n",
      "# 4FGL files downloaded in the 3-day folder: 683\n"
     ]
    }
   ],
   "source": [
    "## Making sure we have the right count\n",
    "\n",
    "print('--------------- 3-day bin ---------------')\n",
    "\n",
    "print('\\n# of sources in the dataframes:')\n",
    "print('dfLSP:', len(dfLSP))\n",
    "print('dfISP:', len(dfISP))\n",
    "print('dfHSP:', len(dfHSP))\n",
    "print('---> total:', len(dfLSP) + len(dfISP) + len(dfHSP))\n",
    "print('dat:', len(dat))\n",
    "\n",
    "print('\\n# of lcs downloaded:')\n",
    "print('lc_downloaded_LSP_3days:', len(lc_downloaded_LSP_3days))\n",
    "print('lc_downloaded_ISP_3days:', len(lc_downloaded_ISP_3days))\n",
    "print('lc_downloaded_HSP_3days:', len(lc_downloaded_HSP_3days))\n",
    "print('---> total:', len(lc_downloaded_LSP_3days) + len(lc_downloaded_ISP_3days) + len(lc_downloaded_HSP_3days))\n",
    "print('lc_downloaded_3days:', len(lc_downloaded_3days))\n",
    "\n",
    "print('\\n# 4FGL files downloaded in the 3-day folder:', len(lc_downloaded_3days))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4004e65f-164e-4605-b5ae-7111da02f0a1",
   "metadata": {},
   "source": [
    "To order the numbers correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "313201db-5674-4e81-a02c-85b0c0111d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_downloaded_HSP_3days.sort()\n",
    "# lc_downloaded_HSP_3days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2224a01e-450c-443f-be60-2ca3e6c09114",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_downloaded_ISP_3days.sort()\n",
    "# lc_downloaded_ISP_3days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35745bd5-1220-4237-a1d0-85e70de734e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_downloaded_LSP_3days.sort()\n",
    "# lc_downloaded_LSP_3days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a77fe4-db48-47fd-bde6-8457c07d12cc",
   "metadata": {},
   "source": [
    "### Weekly bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fa4197f-1a9c-4894-bd5b-e7c0496f357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_downloaded_weekly = os.listdir(f'{path}/lightcurve_downloader/downloaded_lightcurves/weekly_lightcurves') ## weekly_lightcurves folder\n",
    "\n",
    "### Create a list with the downloaded lightcurves that have a corresponding item in the table\n",
    "lc_downloaded_LSP_weekly = [] # low\n",
    "lc_downloaded_ISP_weekly = [] # intermediate\n",
    "lc_downloaded_HSP_weekly = [] # high\n",
    "\n",
    "for file in lc_downloaded_weekly:\n",
    "    ## ---------- Low Synchrotron Peak ----------\n",
    "    if (dfLSP['Source_Name'] == file[5:-5]).any():\n",
    "        lc_downloaded_LSP_weekly.append(f'4FGL+{file[5:-5]}.json')\n",
    "        \n",
    "    ## ---------- Intermediate Synchrotron Peak ----------\n",
    "    if (dfISP['Source_Name'] == file[5:-5]).any():\n",
    "        lc_downloaded_ISP_weekly.append(f'4FGL+{file[5:-5]}.json')\n",
    "        \n",
    "    ## ---------- High Synchrotron Peak ----------\n",
    "    if (dfHSP['Source_Name'] == file[5:-5]).any():\n",
    "        lc_downloaded_HSP_weekly.append(f'4FGL+{file[5:-5]}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7ddfb12-4aff-4993-9ecc-2a4ad7fa1543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------- Weekly bin ---------------\n",
      "\n",
      "# of sources in the dataframes:\n",
      "dfLSP: 1538\n",
      "dfISP: 508\n",
      "dfHSP: 548\n",
      "---> total: 2594\n",
      "dat: 3511\n",
      "\n",
      "# of lcs downloaded:\n",
      "lc_downloaded_LSP_weekly: 465\n",
      "lc_downloaded_ISP_weekly: 60\n",
      "lc_downloaded_HSP_weekly: 66\n",
      "---> total: 591\n",
      "lc_downloaded_weekly: 684\n",
      "\n",
      "# 4FGL files downloaded in the Weekly folder: 684\n"
     ]
    }
   ],
   "source": [
    "## Making sure we have the right count\n",
    "\n",
    "print('\\n--------------- Weekly bin ---------------')\n",
    "\n",
    "print('\\n# of sources in the dataframes:')\n",
    "print('dfLSP:', len(dfLSP))\n",
    "print('dfISP:', len(dfISP))\n",
    "print('dfHSP:', len(dfHSP))\n",
    "print('---> total:', len(dfLSP) + len(dfISP) + len(dfHSP))\n",
    "print('dat:', len(dat))\n",
    "\n",
    "print('\\n# of lcs downloaded:')\n",
    "print('lc_downloaded_LSP_weekly:', len(lc_downloaded_LSP_weekly))\n",
    "print('lc_downloaded_ISP_weekly:', len(lc_downloaded_ISP_weekly))\n",
    "print('lc_downloaded_HSP_weekly:', len(lc_downloaded_HSP_weekly))\n",
    "print('---> total:', len(lc_downloaded_LSP_weekly) + len(lc_downloaded_ISP_weekly) + len(lc_downloaded_HSP_weekly))\n",
    "print('lc_downloaded_weekly:', len(lc_downloaded_weekly))\n",
    "\n",
    "print('\\n# 4FGL files downloaded in the Weekly folder:', len(lc_downloaded_weekly))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9641d1-ecf5-412e-ac7a-005ab58a9913",
   "metadata": {},
   "source": [
    "To order the numbers correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6aac7cd3-58ac-443d-adbb-4cb4ebd4a522",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_downloaded_HSP_weekly.sort()\n",
    "# lc_downloaded_HSP_weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55cb0134-35c9-406e-915e-a6bc433e5472",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_downloaded_ISP_weekly.sort()\n",
    "# lc_downloaded_ISP_weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f892452a-52d4-4e87-b26a-c0e4a554fff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_downloaded_LSP_weekly.sort()\n",
    "# lc_downloaded_LSP_weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a4f092-3b24-449a-9215-4360aa1accb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798d5a21-dc5a-456a-9f5a-9e520b8d27b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
